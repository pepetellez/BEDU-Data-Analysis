{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "s7_r1_casting.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepetellez/BEDU-Data-Analysis/blob/main/Procesamiento-de-Datos-con-Python/7_Transformacion_filtracion_y_ordenamiento_de_datos/s7_r1_casting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaEOYaIuhGt2"
      },
      "source": [
        "## Reto 1: Casting\n",
        "\n",
        "### 1. Objetivos:\n",
        "    - Aplicar diversas técnicas de casting a un dataset nuevo\n",
        " \n",
        "---\n",
        "    \n",
        "### 2. Desarrollo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK6wY7qqhGt6"
      },
      "source": [
        "#### a) Transformando tipos de datos\n",
        "\n",
        "Vamos a trabajar con una versión un poco modificada del dataset que creaste en la sesión pasada. Si bien recuerdas, al final de la sesión pasada automatizamos un programa de Python para obtener un `DataFrame` con todos los objetos que orbitaron cerca de la Tierra en Enero y Febrero de 1995. Para construir este dataset, usamos el API gratuito que ofrece la [NASA](https://api.nasa.gov/).\n",
        "\n",
        "Me tomé la libertad de modificar un poco dicho dataset para que pudiera ser utilizado más efectivamente para los fines de esta sesión. Encontrarás la versión modificada en la ruta '../../Datasets/near_earth_objects-jan_feb_1995-dirty.csv'. Todos los Retos de esta sesión los harás con ese conjunto de datos.\n",
        "\n",
        "Te recomiendo que al finalizar cada reto guardes la nueva versión modificada de tu dataset bajo un nombre que indique el reto realizado (por ejemplo, 'near_earth_objects-jan_feb_1995-reto_1.csv'), para que puedas ir trabajando incrementalmente a través de los retos y no tengas que repetir procesos. Puedes guardar conjuntos de datos en formato `csv` usando el método `DataFrame.to_csv('ruta')`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXdbwtAZhGt7"
      },
      "source": [
        "Tu primer Reto consistirá en seguir los siguientes pasos:\n",
        "\n",
        "1. Lee el dataset y crea un `DataFrame` con él.\n",
        "2. Realiza una pequeña exploración para familiarizarte con él.\n",
        "3. Convierte la columna `relative_velocity.kilometers_per_hour` de `object` a `float64`.\n",
        "4. Convierte la columna `close_approach_date` a tipo de dato `datetime64[ms]` usando el método `astype` y un diccionario de conversión.\n",
        "5. Convierte la columna `epoch_date_close_approach` a tipo de dato `datetime64[ms]` usando el método `to_datetime`.\n",
        "6. Asigna el `DataFrame` resultante a la variable `df_reto_1`.\n",
        "7. Guarda tu resultado en un archivo .csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNNuQX7PhGt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "32f0b194-dde6-4a06-ee0a-3238b11dfab5"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#Lee el dataset y crea un DataFrame con él.\r\n",
        "df_reto_1 = pd.read_csv('drive/MyDrive/Colab Notebooks/Datasets/near_earth_objects-jan_feb_1995-dirty.csv', index_col=0)\r\n",
        "\r\n",
        "#Realiza una pequeña exploración para familiarizarte con él.\r\n",
        "df_reto_1.head()\r\n",
        "df_reto_1.dtypes\r\n",
        "\r\n",
        "#Convierte la columna relative_velocity.kilometers_per_hour de object a float64.\r\n",
        "df_reto_1[\"relative_velocity.kilometers_per_hour\"] = pd.to_numeric(df_reto_1[\"relative_velocity.kilometers_per_hour\"], errors='coerce')\r\n",
        "\r\n",
        "df_reto_1.dtypes\r\n",
        "\r\n",
        "#Convierte la columna close_approach_date a tipo de dato datetime64[ms] usando el método astype y un diccionario de conversión.\r\n",
        "diccionario_de_conversion = {\r\n",
        "    'close_approach_date' : 'datetime64[ms]'\r\n",
        "}\r\n",
        "\r\n",
        "df_reto_1 = df_reto_1.astype(diccionario_de_conversion)\r\n",
        "\r\n",
        "#Convierte la columna epoch_date_close_approach a tipo de dato datetime64[ms] usando el método to_datetime.\r\n",
        "df_reto_1[\"epoch_date_close_approach\"] = pd.to_datetime(df_reto_1[\"epoch_date_close_approach\"], unit='ms')\r\n",
        "\r\n",
        "#Asigna el DataFrame resultante a la variable df_reto_1.\r\n",
        "df_reto_1.to_csv(r'drive/MyDrive/df_reto_7_1.csv')\r\n",
        "\r\n",
        "df_reto_1.dtypes\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e03082bf67bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Lee el dataset y crea un DataFrame con él.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_reto_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/Colab Notebooks/Datasets/near_earth_objects-jan_feb_1995-dirty.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Realiza una pequeña exploración para familiarizarte con él.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Datasets/near_earth_objects-jan_feb_1995-dirty.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6wIiL2yhGt8"
      },
      "source": [
        "Pídele a tu experta la función de verificación `checar_conversiones` (encontrada en el archivo `helpers.py` de la carpeta donde se encuentra este Reto), pégala debajo y corre la celda para verificar tu resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-57fo6RahGt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd4c45b-0381-4179-fd0d-b1823948d2f8"
      },
      "source": [
        "# Pega aquí la función de verificación\n",
        "\n",
        "def checar_conversiones(df_reto_1):\n",
        "    \n",
        "    import pandas as pd\n",
        "    import pandas.api.types as ptypes\n",
        "    \n",
        "    assert ptypes.is_float_dtype(df_reto_1['relative_velocity.kilometers_per_hour']), 'Cuidado... La columna `relative_velocity.kilometers_per_hour` no es de tipo `float64`'\n",
        "    assert ptypes.is_datetime64_any_dtype(df_reto_1['close_approach_date']), 'Cuidado... La columna `close_approach_date` no es de tipo `datetime64[ns]`'\n",
        "    assert ptypes.is_datetime64_any_dtype(df_reto_1['epoch_date_close_approach']), 'Cuidado... La columna `epoch_date_close_approach` no es de tipo `datetime64[ns]'\n",
        "    \n",
        "    print(f'¡Éxito! ¡Todas tus conversiones fueron realizadas adecuadamente!')\n",
        "\n",
        "checar_conversiones(df_reto_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "¡Éxito! ¡Todas tus conversiones fueron realizadas adecuadamente!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFRt-7aGhGt8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}